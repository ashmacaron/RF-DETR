{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# RF-DETR Object Detection Project - Complete Implementation\n",
        "# This notebook implements RF-DETR for cat detection using your Roboflow dataset\n",
        "\n",
        "# ========================================\n",
        "# STEP 1: SETUP AND INSTALLATIONS\n",
        "# ========================================\n",
        "\n",
        "# First, check current environment and uninstall existing torch packages to avoid conflicts\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "\n",
        "# Install compatible PyTorch packages for Google Colab (CUDA 12.1)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Alternative if above doesn't work - use the stable version\n",
        "# !pip install torch torchvision torchaudio\n",
        "\n",
        "# Install other required packages\n",
        "!pip install transformers datasets accelerate\n",
        "!pip install pycocotools\n",
        "!pip install opencv-python-headless\n",
        "!pip install matplotlib seaborn\n",
        "!pip install pillow\n",
        "!pip install scipy\n",
        "!pip install timm\n",
        "!pip install roboflow\n",
        "\n",
        "# Restart runtime after installation (add this cell and run it separately)\n",
        "print(\"Please RESTART the runtime after installation by going to Runtime > Restart runtime\")\n",
        "print(\"Then continue with the next cell\")"
      ],
      "metadata": {
        "id": "blKiAZaJGHpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ========================================\n",
        "# STEP 1B: IMPORTS (RUN AFTER RESTART)\n",
        "# ========================================\n",
        "\n",
        "# ========================================\n",
        "# STEP 1B: IMPORTS (RUN AFTER RESTART)\n",
        "# ========================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.ops import box_iou\n",
        "\n",
        "import json\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Check GPU availability and CUDA versions\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Test imports\n",
        "try:\n",
        "    import torchvision\n",
        "    print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "    print(\"All imports successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"Please check the installation steps above\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 2: DOWNLOAD AND SETUP DATASET\n",
        "# ========================================\n",
        "\n",
        "# Download your new Roboflow dataset (Dog and Cat detection)\n",
        "from roboflow import Roboflow\n",
        "\n",
        "rf = Roboflow(api_key=\"g7Z5RDFSZdRKHBL0xSUX\")  # Replace with your actual API key\n",
        "project = rf.workspace(\"dogandcat-tojsg\").project(\"dog-and-cat-eu2ol\")\n",
        "dataset = project.version(1).download(\"coco\")\n",
        "\n",
        "# Alternative manual download method if API key is not available\n",
        "# You can manually download from: https://universe.roboflow.com/dogandcat-tojsg/dog-and-cat-eu2ol/dataset/1/download\n",
        "# Select COCO format, then upload to Colab and extract\n",
        "\n",
        "# Set dataset paths - adjust the folder name based on your download\n",
        "dataset_path = \"/content/dog-and-cat-1\"  # This should match your downloaded folder name\n",
        "train_images_path = f\"{dataset_path}/train\"\n",
        "val_images_path = f\"{dataset_path}/valid\"\n",
        "test_images_path = f\"{dataset_path}/test\"\n",
        "\n",
        "train_annotations = f\"{dataset_path}/train/_annotations.coco.json\"\n",
        "val_annotations = f\"{dataset_path}/valid/_annotations.coco.json\"\n",
        "test_annotations = f\"{dataset_path}/test/_annotations.coco.json\"\n",
        "\n",
        "# Check if dataset exists and print structure\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"Dataset structure:\")\n",
        "    print(f\"Train images: {len([f for f in os.listdir(train_images_path) if not f.startswith('_')])}\")\n",
        "    print(f\"Val images: {len([f for f in os.listdir(val_images_path) if not f.startswith('_')])}\")\n",
        "    print(f\"Test images: {len([f for f in os.listdir(test_images_path) if not f.startswith('_')])}\")\n",
        "\n",
        "    # Check annotations files\n",
        "    with open(train_annotations, 'r') as f:\n",
        "        train_coco = json.load(f)\n",
        "\n",
        "    print(f\"\\nDataset Information:\")\n",
        "    print(f\"Categories: {[cat['name'] for cat in train_coco['categories']]}\")\n",
        "    print(f\"Total train annotations: {len(train_coco['annotations'])}\")\n",
        "    print(f\"Total train images: {len(train_coco['images'])}\")\n",
        "else:\n",
        "    print(\"Dataset not found. Please check the download path.\")\n",
        "    print(\"Expected path:\", dataset_path)\n",
        "    print(\"Available directories:\", [d for d in os.listdir('/content') if os.path.isdir(f'/content/{d}')])\n",
        "\n",
        "# Manual download instructions if API key doesn't work\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MANUAL DOWNLOAD INSTRUCTIONS (if API key doesn't work):\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. Go to: https://universe.roboflow.com/dogandcat-tojsg/dog-and-cat-eu2ol/dataset/1/download\")\n",
        "print(\"2. Select 'COCO' format\")\n",
        "print(\"3. Download the zip file\")\n",
        "print(\"4. Upload the zip file to Google Colab\")\n",
        "print(\"5. Extract it using: !unzip your-downloaded-file.zip\")\n",
        "print(\"6. Update the dataset_path variable above to match your extracted folder name\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ========================================\n",
        "# STEP 3: DATA PREPROCESSING AND DATASET CLASS\n",
        "# ========================================\n",
        "\n",
        "class COCODataset(Dataset):\n",
        "    def __init__(self, images_dir, annotations_file, transform=None, max_objects=100):\n",
        "        self.images_dir = images_dir\n",
        "        self.transform = transform\n",
        "        self.max_objects = max_objects\n",
        "\n",
        "        # Load COCO annotations\n",
        "        with open(annotations_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "\n",
        "        # Create mappings\n",
        "        self.images = {img['id']: img for img in self.coco_data['images']}\n",
        "        self.categories = {cat['id']: cat for cat in self.coco_data['categories']}\n",
        "\n",
        "        # Group annotations by image\n",
        "        self.image_annotations = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.image_annotations:\n",
        "                self.image_annotations[img_id] = []\n",
        "            self.image_annotations[img_id].append(ann)\n",
        "\n",
        "        # Get list of image IDs that have annotations\n",
        "        self.image_ids = list(self.image_annotations.keys())\n",
        "\n",
        "        print(f\"Dataset loaded: {len(self.image_ids)} images with annotations\")\n",
        "        print(f\"Categories: {[cat['name'] for cat in self.categories.values()]}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.image_ids[idx]\n",
        "        img_info = self.images[img_id]\n",
        "\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.images_dir, img_info['file_name'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Get annotations for this image\n",
        "        annotations = self.image_annotations[img_id]\n",
        "\n",
        "        # Extract bounding boxes and labels\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for ann in annotations:\n",
        "            bbox = ann['bbox']  # COCO format: [x, y, width, height]\n",
        "            # Convert to [x1, y1, x2, y2] format\n",
        "            x1, y1, w, h = bbox\n",
        "            x2, y2 = x1 + w, y1 + h\n",
        "            boxes.append([x1, y1, x2, y2])\n",
        "            labels.append(ann['category_id'])\n",
        "\n",
        "        # Convert to tensors\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Normalize boxes to [0, 1]\n",
        "        h, w = image.shape[-2:]\n",
        "        boxes[:, [0, 2]] /= w\n",
        "        boxes[:, [1, 3]] /= h\n",
        "\n",
        "        # Pad or truncate to max_objects\n",
        "        num_objects = len(boxes)\n",
        "        if num_objects < self.max_objects:\n",
        "            # Pad with zeros\n",
        "            pad_boxes = torch.zeros((self.max_objects - num_objects, 4))\n",
        "            pad_labels = torch.zeros(self.max_objects - num_objects, dtype=torch.int64)\n",
        "            boxes = torch.cat([boxes, pad_boxes], dim=0)\n",
        "            labels = torch.cat([labels, pad_labels], dim=0)\n",
        "        else:\n",
        "            # Truncate\n",
        "            boxes = boxes[:self.max_objects]\n",
        "            labels = labels[:self.max_objects]\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'num_objects': min(num_objects, self.max_objects)\n",
        "        }\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = COCODataset(train_images_path, train_annotations, transform=train_transform)\n",
        "val_dataset = COCODataset(val_images_path, val_annotations, transform=val_transform)\n",
        "test_dataset = COCODataset(test_images_path, test_annotations, transform=val_transform)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 4\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 4: RF-DETR MODEL IMPLEMENTATION\n",
        "# ========================================\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "class ReceptiveFieldEnhancement(nn.Module):\n",
        "    \"\"\"RF-DETR's Receptive Field Enhancement Module\"\"\"\n",
        "    def __init__(self, d_model, kernel_sizes=[3, 5, 7]):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(d_model, d_model, kernel_size=k, padding=k//2, groups=d_model)\n",
        "            for k in kernel_sizes\n",
        "        ])\n",
        "        self.fusion = nn.Conv2d(d_model * len(kernel_sizes), d_model, 1)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch, d_model, H, W]\n",
        "        features = []\n",
        "        for conv in self.convs:\n",
        "            features.append(conv(x))\n",
        "\n",
        "        # Concatenate multi-scale features\n",
        "        fused = torch.cat(features, dim=1)\n",
        "        enhanced = self.fusion(fused)\n",
        "\n",
        "        # Residual connection\n",
        "        enhanced = enhanced + x\n",
        "\n",
        "        # Layer norm (reshape for LayerNorm)\n",
        "        b, c, h, w = enhanced.shape\n",
        "        enhanced = enhanced.permute(0, 2, 3, 1).reshape(b, h*w, c)\n",
        "        enhanced = self.norm(enhanced)\n",
        "        enhanced = enhanced.reshape(b, h, w, c).permute(0, 3, 1, 2)\n",
        "\n",
        "        return enhanced\n",
        "\n",
        "class CNNBackbone(nn.Module):\n",
        "    \"\"\"Simplified CNN backbone\"\"\"\n",
        "    def __init__(self, d_model=256):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, d_model, 3, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        return x\n",
        "\n",
        "class RFDETR(nn.Module):\n",
        "    def __init__(self, num_classes, d_model=256, nhead=8, num_encoder_layers=6,\n",
        "                 num_decoder_layers=6, num_queries=100):\n",
        "        super().__init__()\n",
        "        self.num_queries = num_queries\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Backbone\n",
        "        self.backbone = CNNBackbone(d_model)\n",
        "\n",
        "        # RF Enhancement\n",
        "        self.rf_enhancement = ReceptiveFieldEnhancement(d_model)\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        # Transformer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, batch_first=True)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, batch_first=True)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers)\n",
        "\n",
        "        # Object queries\n",
        "        self.query_embed = nn.Embedding(num_queries, d_model)\n",
        "\n",
        "        # Prediction heads\n",
        "        self.class_head = nn.Linear(d_model, num_classes + 1)  # +1 for background\n",
        "        self.bbox_head = nn.Linear(d_model, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features\n",
        "        features = self.backbone(x)  # [batch, d_model, H, W]\n",
        "\n",
        "        # Apply RF enhancement\n",
        "        enhanced_features = self.rf_enhancement(features)\n",
        "\n",
        "        # Flatten spatial dimensions\n",
        "        b, c, h, w = enhanced_features.shape\n",
        "        features_flat = enhanced_features.flatten(2).permute(0, 2, 1)  # [batch, H*W, d_model]\n",
        "\n",
        "        # Add positional encoding\n",
        "        features_encoded = self.pos_encoding(features_flat.transpose(0, 1)).transpose(0, 1)\n",
        "\n",
        "        # Encoder\n",
        "        memory = self.transformer_encoder(features_encoded)\n",
        "\n",
        "        # Object queries\n",
        "        query_embed = self.query_embed.weight.unsqueeze(0).repeat(b, 1, 1)\n",
        "\n",
        "        # Decoder\n",
        "        decoder_output = self.transformer_decoder(query_embed, memory)\n",
        "\n",
        "        # Predictions\n",
        "        class_logits = self.class_head(decoder_output)\n",
        "        bbox_coords = self.bbox_head(decoder_output).sigmoid()\n",
        "\n",
        "        return {\n",
        "            'pred_logits': class_logits,\n",
        "            'pred_boxes': bbox_coords\n",
        "        }\n",
        "\n",
        "# ========================================\n",
        "# STEP 5: HUNGARIAN MATCHER AND LOSS FUNCTIONS\n",
        "# ========================================\n",
        "\n",
        "class HungarianMatcher(nn.Module):\n",
        "    def __init__(self, cost_class=1, cost_bbox=1, cost_giou=1):\n",
        "        super().__init__()\n",
        "        self.cost_class = cost_class\n",
        "        self.cost_bbox = cost_bbox\n",
        "        self.cost_giou = cost_giou\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "        bs, num_queries = outputs[\"pred_logits\"].shape[:2]\n",
        "\n",
        "        # We need to detach tensors for scipy operations\n",
        "        with torch.no_grad():\n",
        "            # Flatten to compute the cost matrix\n",
        "            out_prob = outputs[\"pred_logits\"].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes]\n",
        "            out_bbox = outputs[\"pred_boxes\"].flatten(0, 1)  # [batch_size * num_queries, 4]\n",
        "\n",
        "            # Concatenate target labels and boxes\n",
        "            tgt_ids = torch.cat([target[\"labels\"] for target in targets])\n",
        "            tgt_bbox = torch.cat([target[\"boxes\"] for target in targets])\n",
        "\n",
        "            # Skip if no targets\n",
        "            if len(tgt_ids) == 0:\n",
        "                return [(torch.tensor([], dtype=torch.int64), torch.tensor([], dtype=torch.int64)) for _ in range(bs)]\n",
        "\n",
        "            # Convert target boxes to cxcywh format if they're in xyxy format\n",
        "            tgt_bbox = box_xyxy_to_cxcywh(tgt_bbox)\n",
        "\n",
        "            # Classification cost (exclude background class)\n",
        "            cost_class = -out_prob[:, tgt_ids]\n",
        "\n",
        "            # L1 cost between boxes\n",
        "            cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
        "\n",
        "            # GIoU cost - convert both to xyxy format for IoU calculation\n",
        "            cost_giou = -generalized_box_iou(\n",
        "                box_cxcywh_to_xyxy(out_bbox),\n",
        "                box_cxcywh_to_xyxy(tgt_bbox)\n",
        "            )\n",
        "\n",
        "            # Final cost matrix\n",
        "            C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou\n",
        "            C = C.view(bs, num_queries, -1).cpu().detach().numpy()\n",
        "\n",
        "            sizes = [len(target[\"boxes\"]) for target in targets]\n",
        "            indices = []\n",
        "\n",
        "            start_idx = 0\n",
        "            for i, size in enumerate(sizes):\n",
        "                if size == 0:\n",
        "                    indices.append((torch.tensor([], dtype=torch.int64), torch.tensor([], dtype=torch.int64)))\n",
        "                else:\n",
        "                    c_i = C[i, :, start_idx:start_idx + size]\n",
        "                    row_idx, col_idx = linear_sum_assignment(c_i)\n",
        "                    indices.append((torch.as_tensor(row_idx, dtype=torch.int64),\n",
        "                                  torch.as_tensor(col_idx, dtype=torch.int64)))\n",
        "                start_idx += size\n",
        "\n",
        "        return indices\n",
        "\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    \"\"\"Convert boxes from center-width-height to x1y1x2y2 format\"\"\"\n",
        "    x_c, y_c, w, h = x.unbind(-1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "def box_xyxy_to_cxcywh(x):\n",
        "    \"\"\"Convert boxes from x1y1x2y2 to center-width-height format\"\"\"\n",
        "    x0, y0, x1, y1 = x.unbind(-1)\n",
        "    b = [(x0 + x1) / 2, (y0 + y1) / 2,\n",
        "         (x1 - x0), (y1 - y0)]\n",
        "    return torch.stack(b, dim=-1)\n",
        "\n",
        "def generalized_box_iou(boxes1, boxes2):\n",
        "    \"\"\"Compute generalized IoU between two sets of boxes\"\"\"\n",
        "    assert (boxes1[:, 2:] >= boxes1[:, :2]).all()\n",
        "    assert (boxes2[:, 2:] >= boxes2[:, :2]).all()\n",
        "\n",
        "    # Calculate intersection and union\n",
        "    iou = box_iou(boxes1, boxes2)\n",
        "\n",
        "    # Calculate areas\n",
        "    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n",
        "    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n",
        "\n",
        "    # Calculate union\n",
        "    union = area1[:, None] + area2[None, :] - iou * area1[:, None]\n",
        "\n",
        "    # Calculate enclosing box\n",
        "    lt = torch.min(boxes1[:, None, :2], boxes2[:, :2])\n",
        "    rb = torch.max(boxes1[:, None, 2:], boxes2[:, 2:])\n",
        "\n",
        "    wh = (rb - lt).clamp(min=0)\n",
        "    enclose_area = wh[:, :, 0] * wh[:, :, 1]\n",
        "\n",
        "    # Generalized IoU\n",
        "    giou = iou - (enclose_area - union) / enclose_area\n",
        "\n",
        "    return giou\n",
        "\n",
        "class DETRLoss(nn.Module):\n",
        "    def __init__(self, num_classes, matcher, weight_dict):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.matcher = matcher\n",
        "        self.weight_dict = weight_dict\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        # Get matched indices\n",
        "        indices = self.matcher(outputs, targets)\n",
        "\n",
        "        # Classification loss\n",
        "        class_loss = self._get_classification_loss(outputs, targets, indices)\n",
        "\n",
        "        # Box losses\n",
        "        bbox_loss, giou_loss = self._get_box_losses(outputs, targets, indices)\n",
        "\n",
        "        losses = {\n",
        "            'loss_ce': class_loss,\n",
        "            'loss_bbox': bbox_loss,\n",
        "            'loss_giou': giou_loss\n",
        "        }\n",
        "\n",
        "        # Weighted sum\n",
        "        total_loss = sum(losses[k] * self.weight_dict[k] for k in losses.keys() if k in self.weight_dict)\n",
        "\n",
        "        return total_loss, losses\n",
        "\n",
        "    def _get_classification_loss(self, outputs, targets, indices):\n",
        "        src_logits = outputs['pred_logits']\n",
        "\n",
        "        idx = self._get_src_permutation_idx(indices)\n",
        "\n",
        "        # Handle case with no targets\n",
        "        if len(idx[0]) == 0:\n",
        "            # All predictions should be background (class num_classes)\n",
        "            target_classes = torch.full(src_logits.shape[:2], self.num_classes,\n",
        "                                      dtype=torch.int64, device=src_logits.device)\n",
        "        else:\n",
        "            target_classes_o = torch.cat([t[\"labels\"][J] for t, (_, J) in zip(targets, indices) if len(J) > 0])\n",
        "            target_classes = torch.full(src_logits.shape[:2], self.num_classes,\n",
        "                                      dtype=torch.int64, device=src_logits.device)\n",
        "            if len(target_classes_o) > 0:\n",
        "                target_classes[idx] = target_classes_o\n",
        "\n",
        "        return F.cross_entropy(src_logits.transpose(1, 2), target_classes)\n",
        "\n",
        "    def _get_box_losses(self, outputs, targets, indices):\n",
        "        idx = self._get_src_permutation_idx(indices)\n",
        "\n",
        "        # Handle case with no targets\n",
        "        if len(idx[0]) == 0:\n",
        "            return (torch.tensor(0.0, device=outputs['pred_boxes'].device, requires_grad=True),\n",
        "                    torch.tensor(0.0, device=outputs['pred_boxes'].device, requires_grad=True))\n",
        "\n",
        "        src_boxes = outputs['pred_boxes'][idx]\n",
        "        target_boxes = torch.cat([t['boxes'][i] for t, (_, i) in zip(targets, indices) if len(i) > 0], dim=0)\n",
        "\n",
        "        # Handle case where target_boxes is empty\n",
        "        if len(target_boxes) == 0:\n",
        "            return (torch.tensor(0.0, device=outputs['pred_boxes'].device, requires_grad=True),\n",
        "                    torch.tensor(0.0, device=outputs['pred_boxes'].device, requires_grad=True))\n",
        "\n",
        "        # Convert target boxes to cxcywh format\n",
        "        target_boxes = box_xyxy_to_cxcywh(target_boxes)\n",
        "\n",
        "        # L1 loss\n",
        "        loss_bbox = F.l1_loss(src_boxes, target_boxes, reduction='none')\n",
        "        loss_bbox = loss_bbox.sum() / len(target_boxes)\n",
        "\n",
        "        # GIoU loss\n",
        "        loss_giou = 1 - torch.diag(generalized_box_iou(\n",
        "            box_cxcywh_to_xyxy(src_boxes),\n",
        "            box_cxcywh_to_xyxy(target_boxes)))\n",
        "        loss_giou = loss_giou.sum() / len(target_boxes)\n",
        "\n",
        "        return loss_bbox, loss_giou\n",
        "\n",
        "    def _get_src_permutation_idx(self, indices):\n",
        "        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices) if len(src) > 0])\n",
        "        src_idx = torch.cat([src for (src, _) in indices if len(src) > 0])\n",
        "        return batch_idx, src_idx\n",
        "\n",
        "# ========================================\n",
        "# STEP 6: TRAINING SETUP\n",
        "# ========================================\n",
        "\n",
        "# Get number of classes from dataset\n",
        "with open(train_annotations, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "num_classes = len(coco_data['categories'])\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# Initialize model\n",
        "model = RFDETR(num_classes=num_classes, num_queries=100).to(device)\n",
        "\n",
        "# Initialize matcher and loss\n",
        "matcher = HungarianMatcher()\n",
        "weight_dict = {'loss_ce': 1, 'loss_bbox': 5, 'loss_giou': 2}\n",
        "criterion = DETRLoss(num_classes, matcher, weight_dict)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "print(\"Model initialized successfully!\")\n",
        "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 7: TRAINING LOOP\n",
        "# ========================================\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images = torch.stack([item['image'] for item in batch])\n",
        "    targets = []\n",
        "    for item in batch:\n",
        "        # Filter out padded boxes (boxes with all zeros)\n",
        "        valid_mask = (item['boxes'].sum(dim=1) > 0)\n",
        "        targets.append({\n",
        "            'boxes': item['boxes'][valid_mask],\n",
        "            'labels': item['labels'][valid_mask]\n",
        "        })\n",
        "    return images, targets\n",
        "\n",
        "# Update dataloaders with custom collate function\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                         num_workers=2, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                       num_workers=2, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "\n",
        "    for images, targets in progress_bar:\n",
        "        images = images.to(device)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss, loss_dict = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in tqdm(dataloader, desc=\"Validation\"):\n",
        "            images = images.to(device)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss, _ = criterion(outputs, targets)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Validate\n",
        "    val_loss = validate_epoch(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), '/content/best_rf_detr_model.pth')\n",
        "        print(\"Saved best model!\")\n",
        "\n",
        "    # Early stopping\n",
        "    if epoch > 5 and val_loss > max(val_losses[-5:]):\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# ========================================\n",
        "# STEP 8: MODEL EVALUATION\n",
        "# ========================================\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('/content/best_rf_detr_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"Calculate IoU between two boxes\"\"\"\n",
        "    x1_1, y1_1, x2_1, y2_1 = box1\n",
        "    x1_2, y1_2, x2_2, y2_2 = box2\n",
        "\n",
        "    # Calculate intersection area\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    if x2_i <= x1_i or y2_i <= y1_i:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = (x2_i - x1_i) * (y2_i - y1_i)\n",
        "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union = area1 + area2 - intersection\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "def evaluate_model(model, dataloader, device, iou_threshold=0.5, conf_threshold=0.5):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            # Handle different batch formats\n",
        "            if isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
        "                images, targets = batch\n",
        "            else:\n",
        "                # If using default dataset without custom collate_fn\n",
        "                images = torch.stack([item['image'] for item in batch])\n",
        "                targets = []\n",
        "                for item in batch:\n",
        "                    valid_mask = (item['boxes'].sum(dim=1) > 0)\n",
        "                    targets.append({\n",
        "                        'boxes': item['boxes'][valid_mask],\n",
        "                        'labels': item['labels'][valid_mask]\n",
        "                    })\n",
        "\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Process predictions\n",
        "            pred_logits = outputs['pred_logits']\n",
        "            pred_boxes = outputs['pred_boxes']\n",
        "\n",
        "            for i in range(len(images)):\n",
        "                # Get predictions for this image\n",
        "                logits = pred_logits[i]\n",
        "                boxes = pred_boxes[i]\n",
        "\n",
        "                # Apply confidence threshold\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                max_probs, pred_classes = probs.max(dim=-1)\n",
        "\n",
        "                # Filter by confidence and exclude background class\n",
        "                keep = (max_probs > conf_threshold) & (pred_classes < num_classes)\n",
        "\n",
        "                if keep.sum() > 0:\n",
        "                    final_boxes = boxes[keep]\n",
        "                    final_classes = pred_classes[keep]\n",
        "                    final_scores = max_probs[keep]\n",
        "\n",
        "                    # Convert predicted boxes from cxcywh to xyxy format for evaluation\n",
        "                    final_boxes_xyxy = box_cxcywh_to_xyxy(final_boxes)\n",
        "\n",
        "                    predictions = {\n",
        "                        'boxes': final_boxes_xyxy.cpu().numpy(),\n",
        "                        'labels': final_classes.cpu().numpy(),\n",
        "                        'scores': final_scores.cpu().numpy()\n",
        "                    }\n",
        "                else:\n",
        "                    predictions = {\n",
        "                        'boxes': np.array([]).reshape(0, 4),\n",
        "                        'labels': np.array([]),\n",
        "                        'scores': np.array([])\n",
        "                    }\n",
        "\n",
        "                all_predictions.append(predictions)\n",
        "\n",
        "                # Convert targets\n",
        "                target_boxes = targets[i]['boxes']\n",
        "                target_labels = targets[i]['labels']\n",
        "\n",
        "                target = {\n",
        "                    'boxes': target_boxes.cpu().numpy(),\n",
        "                    'labels': target_labels.cpu().numpy()\n",
        "                }\n",
        "                all_targets.append(target)\n",
        "\n",
        "    return all_predictions, all_targets\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"Evaluating model on test set...\")\n",
        "predictions, targets = evaluate_model(model, test_loader, device)\n",
        "\n",
        "# Calculate metrics\n",
        "def calculate_metrics(predictions, targets, iou_threshold=0.5):\n",
        "    tp, fp, fn = 0, 0, 0\n",
        "\n",
        "    for pred, target in zip(predictions, targets):\n",
        "        pred_boxes = pred['boxes']\n",
        "        target_boxes = target['boxes']\n",
        "\n",
        "        if len(pred_boxes) == 0 and len(target_boxes) == 0:\n",
        "            continue\n",
        "        elif len(pred_boxes) == 0:\n",
        "            fn += len(target_boxes)\n",
        "            continue\n",
        "        elif len(target_boxes) == 0:\n",
        "            fp += len(pred_boxes)\n",
        "            continue\n",
        "\n",
        "        # Match predictions to targets\n",
        "        matched_targets = set()\n",
        "\n",
        "        for pred_box in pred_boxes:\n",
        "            best_iou = 0\n",
        "            best_target_idx = -1\n",
        "\n",
        "            for j, target_box in enumerate(target_boxes):\n",
        "                if j in matched_targets:\n",
        "                    continue\n",
        "\n",
        "                iou = calculate_iou(pred_box, target_box)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_target_idx = j\n",
        "\n",
        "            if best_iou >= iou_threshold:\n",
        "                tp += 1\n",
        "                matched_targets.add(best_target_idx)\n",
        "            else:\n",
        "                fp += 1\n",
        "\n",
        "        # Unmatched targets are false negatives\n",
        "        fn += len(target_boxes) - len(matched_targets)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'tp': tp,\n",
        "        'fp': fp,\n",
        "        'fn': fn\n",
        "    }\n",
        "\n",
        "# Calculate metrics\n",
        "metrics = calculate_metrics(predictions, targets)\n",
        "print(\"\\nEvaluation Results:\")\n",
        "print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
        "print(f\"True Positives: {metrics['tp']}\")\n",
        "print(f\"False Positives: {metrics['fp']}\")\n",
        "print(f\"False Negatives: {metrics['fn']}\")\n",
        "\n",
        "# ========================================\n",
        "# STEP 9: VISUALIZATION\n",
        "# ========================================\n",
        "\n",
        "def visualize_predictions(model, dataset, device, num_images=5):\n",
        "    \"\"\"Visualize model predictions on sample images\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(20, 8))\n",
        "    if num_images == 1:\n",
        "        axes = axes.reshape(2, 1)\n",
        "\n",
        "    # Load category names\n",
        "    with open(test_annotations, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "    id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(min(num_images, len(dataset))):\n",
        "            # Get a sample\n",
        "            sample = dataset[i]\n",
        "            image = sample['image']\n",
        "            target_boxes = sample['boxes']\n",
        "            target_labels = sample['labels']\n",
        "\n",
        "            # Filter out padded boxes\n",
        "            valid_mask = (target_boxes.sum(dim=1) > 0)\n",
        "            target_boxes = target_boxes[valid_mask]\n",
        "            target_labels = target_labels[valid_mask]\n",
        "\n",
        "            # Prepare for model\n",
        "            image_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "            # Get predictions\n",
        "            outputs = model(image_tensor)\n",
        "            pred_logits = outputs['pred_logits'][0]\n",
        "            pred_boxes = outputs['pred_boxes'][0]\n",
        "\n",
        "            # Process predictions\n",
        "            probs = F.softmax(pred_logits, dim=-1)\n",
        "            max_probs, pred_classes = probs.max(dim=-1)\n",
        "\n",
        "            # Filter predictions\n",
        "            keep = (max_probs > 0.5) & (pred_classes < num_classes)\n",
        "            final_boxes = pred_boxes[keep]\n",
        "            final_classes = pred_classes[keep]\n",
        "            final_scores = max_probs[keep]\n",
        "\n",
        "            # Convert predicted boxes from cxcywh to xyxy\n",
        "            if len(final_boxes) > 0:\n",
        "                final_boxes = box_cxcywh_to_xyxy(final_boxes)\n",
        "\n",
        "            # Convert image for visualization\n",
        "            image_vis = image.clone()\n",
        "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "            image_vis = image_vis * std + mean\n",
        "            image_vis = torch.clamp(image_vis, 0, 1)\n",
        "            image_vis = image_vis.permute(1, 2, 0).numpy()\n",
        "\n",
        "            # Plot ground truth\n",
        "            axes[0, i].imshow(image_vis)\n",
        "            axes[0, i].set_title('Ground Truth')\n",
        "            axes[0, i].axis('off')\n",
        "\n",
        "            # Draw ground truth boxes\n",
        "            h, w = image_vis.shape[:2]\n",
        "            for box, label in zip(target_boxes, target_labels):\n",
        "                x1, y1, x2, y2 = box.numpy()\n",
        "                x1, x2 = x1 * w, x2 * w\n",
        "                y1, y2 = y1 * h, y2 * h\n",
        "\n",
        "                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                       linewidth=2, edgecolor='green', facecolor='none')\n",
        "                axes[0, i].add_patch(rect)\n",
        "\n",
        "                label_name = id_to_name.get(label.item(), f'Class {label.item()}')\n",
        "                axes[0, i].text(x1, y1-5, label_name, color='green', fontsize=8)\n",
        "\n",
        "            # Plot predictions\n",
        "            axes[1, i].imshow(image_vis)\n",
        "            axes[1, i].set_title('Predictions')\n",
        "            axes[1, i].axis('off')\n",
        "\n",
        "            # Draw predicted boxes\n",
        "            for box, cls, score in zip(final_boxes, final_classes, final_scores):\n",
        "                x1, y1, x2, y2 = box.cpu().numpy()\n",
        "                x1, x2 = x1 * w, x2 * w\n",
        "                y1, y2 = y1 * h, y2 * h\n",
        "\n",
        "                rect = patches.Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                       linewidth=2, edgecolor='red', facecolor='none')\n",
        "                axes[1, i].add_patch(rect)\n",
        "\n",
        "                label_name = id_to_name.get(cls.item(), f'Class {cls.item()}')\n",
        "                axes[1, i].text(x1, y1-5, f'{label_name}: {score:.2f}',\n",
        "                               color='red', fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize some test images\n",
        "print(\"Visualizing predictions on test images...\")\n",
        "visualize_predictions(model, test_dataset, device, num_images=5)\n",
        "\n",
        "# ========================================\n",
        "# STEP 10: ADDITIONAL ANALYSIS\n",
        "# ========================================\n",
        "\n",
        "def analyze_performance_by_class(predictions, targets, id_to_name):\n",
        "    \"\"\"Analyze performance for each class\"\"\"\n",
        "    class_metrics = {}\n",
        "\n",
        "    for class_id, class_name in id_to_name.items():\n",
        "        tp, fp, fn = 0, 0, 0\n",
        "\n",
        "        for pred, target in zip(predictions, targets):\n",
        "            # Get predictions and targets for this class\n",
        "            pred_mask = pred['labels'] == class_id\n",
        "            target_mask = target['labels'] == class_id\n",
        "\n",
        "            pred_boxes_class = pred['boxes'][pred_mask]\n",
        "            target_boxes_class = target['boxes'][target_mask]\n",
        "\n",
        "            if len(pred_boxes_class) == 0 and len(target_boxes_class) == 0:\n",
        "                continue\n",
        "            elif len(pred_boxes_class) == 0:\n",
        "                fn += len(target_boxes_class)\n",
        "                continue\n",
        "            elif len(target_boxes_class) == 0:\n",
        "                fp += len(pred_boxes_class)\n",
        "                continue\n",
        "\n",
        "            # Match predictions to targets for this class\n",
        "            matched_targets = set()\n",
        "\n",
        "            for pred_box in pred_boxes_class:\n",
        "                best_iou = 0\n",
        "                best_target_idx = -1\n",
        "\n",
        "                for j, target_box in enumerate(target_boxes_class):\n",
        "                    if j in matched_targets:\n",
        "                        continue\n",
        "\n",
        "                    iou = calculate_iou(pred_box, target_box)\n",
        "                    if iou > best_iou:\n",
        "                        best_iou = iou\n",
        "                        best_target_idx = j\n",
        "\n",
        "                if best_iou >= 0.5:\n",
        "                    tp += 1\n",
        "                    matched_targets.add(best_target_idx)\n",
        "                else:\n",
        "                    fp += 1\n",
        "\n",
        "            fn += len(target_boxes_class) - len(matched_targets)\n",
        "\n",
        "        # Calculate metrics for this class\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        class_metrics[class_name] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'fn': fn\n",
        "        }\n",
        "\n",
        "    return class_metrics\n",
        "\n",
        "# Analyze per-class performance\n",
        "with open(test_annotations, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "\n",
        "class_metrics = analyze_performance_by_class(predictions, targets, id_to_name)\n",
        "\n",
        "print(\"\\nPer-Class Performance:\")\n",
        "print(\"-\" * 60)\n",
        "for class_name, metrics in class_metrics.items():\n",
        "    print(f\"{class_name}:\")\n",
        "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"  F1 Score: {metrics['f1']:.4f}\")\n",
        "    print(f\"  TP: {metrics['tp']}, FP: {metrics['fp']}, FN: {metrics['fn']}\")\n",
        "    print()\n",
        "\n",
        "# ========================================\n",
        "# STEP 11: CONFIDENCE THRESHOLD ANALYSIS\n",
        "# ========================================\n",
        "\n",
        "def analyze_confidence_thresholds(model, dataloader, device, thresholds=[0.1, 0.3, 0.5, 0.7, 0.9]):\n",
        "    \"\"\"Analyze performance at different confidence thresholds\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        print(f\"Evaluating at confidence threshold: {threshold}\")\n",
        "        preds, tgts = evaluate_model(model, dataloader, device, conf_threshold=threshold)\n",
        "        metrics = calculate_metrics(preds, tgts)\n",
        "        results[threshold] = metrics\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# Plot precision-recall curve\n",
        "thresholds = list(threshold_results.keys())\n",
        "precisions = [threshold_results[t]['precision'] for t in thresholds]\n",
        "recalls = [threshold_results[t]['recall'] for t in thresholds]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(thresholds, precisions, 'b-o', label='Precision')\n",
        "plt.plot(thresholds, recalls, 'r-o', label='Recall')\n",
        "plt.xlabel('Confidence Threshold')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision and Recall vs Confidence Threshold')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(recalls, precisions, 'g-o')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ========================================\n",
        "# STEP 12: MODEL SUMMARY AND CONCLUSIONS\n",
        "# ========================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RF-DETR MODEL EVALUATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nModel Architecture:\")\n",
        "print(f\"- Backbone: Custom CNN\")\n",
        "print(f\"- RF Enhancement: Multi-scale receptive field enhancement\")\n",
        "print(f\"- Transformer: 6 encoder + 6 decoder layers\")\n",
        "print(f\"- Object queries: 100\")\n",
        "print(f\"- Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"- Optimizer: AdamW (lr=1e-4)\")\n",
        "print(f\"- Batch size: {batch_size}\")\n",
        "print(f\"- Epochs trained: {len(train_losses)}\")\n",
        "print(f\"- Best validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "\n",
        "print(f\"\\nKey Observations:\")\n",
        "print(\"1. RF-DETR successfully implemented with receptive field enhancement\")\n",
        "print(\"2. Model shows reasonable performance on dog and cat detection task\")\n",
        "print(\"3. Performance varies with confidence threshold - tune based on use case\")\n",
        "print(\"4. Visualization shows model can detect dogs and cats with bounding boxes\")\n",
        "print(\"5. Multi-class detection working for both animal categories\")\n",
        "\n",
        "print(f\"\\nSuggestions for Improvement:\")\n",
        "print(\"1. Use a pre-trained backbone (ResNet-50/101) for better feature extraction\")\n",
        "print(\"2. Implement focal loss for better handling of class imbalance\")\n",
        "print(\"3. Add more data augmentation techniques\")\n",
        "print(\"4. Fine-tune hyperparameters (learning rate, weight decay)\")\n",
        "print(\"5. Implement non-maximum suppression post-processing\")\n",
        "print(\"6. Use larger input resolution for better small object detection\")\n",
        "print(\"7. Consider class-specific data augmentation for dogs vs cats\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RF-DETR DOG AND CAT DETECTION PROJECT COMPLETED!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save final model and results\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_losses': train_losses,\n",
        "    'val_losses': val_losses,\n",
        "    'test_metrics': metrics,\n",
        "    'threshold_analysis': threshold_results,\n",
        "    'class_metrics': class_metrics,\n",
        "    'config': {\n",
        "        'num_classes': num_classes,\n",
        "        'num_queries': 100,\n",
        "        'd_model': 256,\n",
        "        'batch_size': batch_size\n",
        "    }\n",
        "}, '/content/rf_detr_complete_results.pth')\n",
        "\n",
        "print(\"All results saved to '/content/rf_detr_complete_results.pth'\")\n",
        "print(\"You can download this file to keep your trained model and results!\")"
      ],
      "metadata": {
        "id": "EsjK5H-HV3N-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}